{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Model Prediction Results.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"fMi71ZrCzrjw"},"source":["# MODEL PREDICTION\n","\n","We will predict the results of prediction on the test images provided in the competition using the best models generated from each of the following approaches "]},{"cell_type":"markdown","metadata":{"id":"S11Sm6n1zrjw"},"source":["Approaches followed for model creation\n","1. Creating the Self designned CNN from scratch \n","2. Using the Vgg16 architecture as a base and fine tuning the last layer"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"2SfXKZu_zrj4"},"source":["#Importing all the requied libraries , which I used in this Project. \n","import os\n","import json\n","from keras.models import load_model\n","import pandas as pd\n","import pickle\n","import numpy as np\n","import shutil\n","\n","from keras.preprocessing import image                  \n","from tqdm.notebook import tqdm\n","from PIL import ImageFile                            \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tLVJu_tB4hc-"},"source":["# Defining the train,test and model directories\n","\n","* We will create the directories for train,test and model training paths if not present"]},{"cell_type":"code","metadata":{"id":"KDQjaAxRzrj4"},"source":["# That's are my model path directories\n","BASE_MODEL_PATH = os.path.join(os.getcwd(),\"model\")\n","TEST_DIR = os.path.join(os.getcwd(),\"csv_files\",\"test.csv\")\n","PREDICT_DIR = os.path.join(os.getcwd(),\"pred_dir\")\n","PICKLE_DIR = os.path.join(os.getcwd(),\"pickle_files\")\n","JSON_DIR = os.path.join(os.getcwd(),\"json_files\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M9-_7UxtzrkA"},"source":["# Using condition to confirm that have all above defined directories are their or not . \n","if not os.path.exists(PREDICT_DIR):\n","    os.makedirs(PREDICT_DIR)\n","else:\n","    shutil.rmtree(PREDICT_DIR)\n","    os.makedirs(PREDICT_DIR)\n","if not os.path.exists(JSON_DIR):\n","    os.makedirs(JSON_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a9d_TrtAzrkA"},"source":["# Prediction using-->Self Trained Model (CNN Scratch)"]},{"cell_type":"code","metadata":{"id":"AMGOWfyYzrkI","outputId":"563f038c-02e4-47bc-9ccd-694bfa36cb98"},"source":["# Generate path with self trained model weight\n","BEST_MODEL = os.path.join(BASE_MODEL_PATH,\"self_trained\",\"distracted-23-0.99.hdf5\")\n","model = load_model(BEST_MODEL)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 128, 128, 64)      832       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 64, 64, 64)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 64, 64, 128)       32896     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 32, 32, 256)       131328    \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 16, 16, 256)       0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 16, 16, 512)       524800    \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 8, 8, 512)         0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 8, 8, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 32768)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 500)               16384500  \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 500)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                5010      \n","=================================================================\n","Total params: 17,079,366\n","Trainable params: 17,079,366\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wx_Y_dKOzrkQ","outputId":"15b6b50d-a762-475c-fbca-b85c22ddeab1"},"source":["# Read the all test images \n","data_test = pd.read_csv(os.path.join(TEST_DIR))\n","#testing on the only 10000 images as loading the all test images requires ram>8gb\n","data_test = data_test[:10000] \n","data_test.info()\n","# data_test.describe()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 100 entries, 0 to 99\n","Data columns (total 2 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   FileName   100 non-null    object\n"," 1   ClassName  100 non-null    object\n","dtypes: object(2)\n","memory usage: 1.7+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"in42s42ozrkQ","outputId":"3e1751c4-8074-4e44-c093-b4af3d08de59"},"source":["# Converts a Python object hierarchy into a byte stream written to a buffer or to a disk file.\n","with open(os.path.join(PICKLE_DIR,\"labels_list.pkl\"),\"rb\") as handle:\n","    labels_id = pickle.load(handle)\n","print(labels_id)\n","# labels_id = {'c1': 0, 'c6': 1, 'c5': 2, 'c8': 3, 'c3': 4, 'c0': 5, 'c7': 6, 'c2': 7, 'c4': 8, 'c9': 9}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'c5': 0, 'c8': 1, 'c1': 2, 'c0': 3, 'c4': 4, 'c3': 5, 'c6': 6, 'c9': 7, 'c2': 8, 'c7': 9}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CGPAxfxv1-FW"},"source":["# Labeling & Testing\n","                    Using library function ImageFile to make file or directory situable for pictures. "]},{"cell_type":"code","metadata":{"colab":{"referenced_widgets":["56a54f4c32e04596a0a02240f8d6846e"]},"id":"pZjepM2dzrkY","outputId":"f84a960b-cd6d-4e33-a155-60a7b0c27937"},"source":["def path_to_tensor(img_path):\n","    # loads RGB image as PIL.Image.Image type\n","    img = image.load_img(img_path, target_size=(128, 128))\n","    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n","    x = image.img_to_array(img)\n","    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n","    return np.expand_dims(x, axis=0)\n","\n","def paths_to_tensor(img_paths):\n","    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n","    return np.vstack(list_of_tensors)\n","\n","ImageFile.LOAD_TRUNCATED_IMAGES = True  \n","test_tensors = paths_to_tensor(data_test.iloc[:,0]).astype('float32')/255 - 0.5"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56a54f4c32e04596a0a02240f8d6846e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"a0KX-Vo_zrkY"},"source":["# predicting model at both train and valid with single single animated progress bar \n","ypred_test = model.predict(test_tensors,verbose=1)\n","ypred_class = np.argmax(ypred_test,axis=1)\n","\n","id_labels = dict()\n","for class_name,idx in labels_id.items():\n","    id_labels[idx] = class_name\n","print(id_labels) \n","\n","for i in range(data_test.shape[0]):\n","    data_test.iloc[i,1] = id_labels[ypred_class[i]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Pu0-AZNzrkY"},"source":["#to create a human readable and understandable class_name \n","class_name = dict()\n","class_name[\"c0\"] = \"SAFE_DRIVING\"\n","class_name[\"c1\"] = \"TEXTING_RIGHT\"\n","class_name[\"c2\"] = \"TALKING_PHONE_RIGHT\"\n","class_name[\"c3\"] = \"TEXTING_LEFT\"\n","class_name[\"c4\"] = \"TALKING_PHONE_LEFT\"\n","class_name[\"c5\"] = \"OPERATING_RADIO\"\n","class_name[\"c6\"] = \"DRINKING\"\n","class_name[\"c7\"] = \"REACHING_BEHIND\"\n","class_name[\"c8\"] = \"HAIR_AND_MAKEUP\"\n","class_name[\"c9\"] = \"TALKING_TO_PASSENGER\"\n","\n","\n","with open(os.path.join(JSON_DIR,'class_name_map.json'),'w') as secret_input:\n","    json.dump(class_name,secret_input,indent=4,sort_keys=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h68d81myzrkg"},"source":["# creating the prediction results for the image classification and shifting the predicted images to another folder\n","#with renamed filename having the class name predicted for that image using model\n","with open(os.path.join(JSON_DIR,'class_name_map.json')) as secret_input:\n","    info = json.load(secret_input)\n","\n","\n","for i in range(data_test.shape[0]):\n","    new_name = data_test.iloc[i,0].split(\"/\")[-1].split(\".\")[0]+\"_\"+info[data_test.iloc[i,1]]+\".jpg\"\n","    shutil.copy(data_test.iloc[i,0],os.path.join(PREDICT_DIR,new_name))\n","    \n","#saving the model predicted results into a csv file\n","data_test.to_csv(os.path.join(os.getcwd(),\"csv_files\",\"short_test_result.csv\"),index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X8hzYsEJzrkg"},"source":[""],"execution_count":null,"outputs":[]}]}